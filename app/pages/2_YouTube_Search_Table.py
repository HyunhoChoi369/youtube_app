# pages/2_YouTube_Search_Table.py
import json
import pandas as pd
import requests
import streamlit as st
import config, utils

st.set_page_config(page_title="YouTube ê²€ìƒ‰ ì‹œíŠ¸", layout="wide")
st.title("ğŸ“º YouTube ê²€ìƒ‰ ì‹œíŠ¸ (Cloud Run)")

config.render_key_inputs()
ENDPOINT = config.get("YT_SEARCH_ENDPOINT") or "https://search-youtube-417935223154.europe-west1.run.app/search-shorts"

# ì„¸ì…˜ ìƒíƒœ ì¤€ë¹„
if "yt_results" not in st.session_state:
    st.session_state["yt_results"] = pd.DataFrame()

search_tab, sort_tab = st.tabs(["ğŸ” ê²€ìƒ‰", "â†•ï¸ ì •ë ¬/ë­í‚¹"])

# =========================
# ğŸ” ê²€ìƒ‰ íƒ­
# =========================
with search_tab:
    st.subheader("ê²€ìƒ‰ ì˜µì…˜ (Cloud Run POST í˜¸ì¶œ)")

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    with c1:
        keyword = st.text_input("keyword*", placeholder="ì˜ˆ: debate, êµ­íšŒ ë³¸íšŒì˜, economy")
    with c2:
        days = st.number_input("days", min_value=1, max_value=30, value=7, step=1)
    with c3:
        max_results = st.number_input("max_results", min_value=1, max_value=200, value=100, step=1)
    with c4:
        top_n = st.number_input("top_n", min_value=1, max_value=50, value=10, step=1)
    with c5:
        rank_by = st.selectbox("rank_by", ["score","view_count","views_per_hour","like_count","likes_per_view"], index=0)
    with c6:
        fmt = st.selectbox("format", ["json","values"], index=0)

    run = st.button("ê²€ìƒ‰ ì‹¤í–‰", type="primary", use_container_width=True)

    if run:
        if not keyword.strip():
            st.warning("keywordëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        else:
            payload = {
                "keyword": keyword.strip(),
                "days": int(days),
                "max_results": int(max_results),
                "top_n": int(top_n),
                "rank_by": rank_by,
                "format": fmt
            }
            with st.spinner("Cloud Run í˜¸ì¶œ ì¤‘..."):
                try:
                    resp = requests.post(ENDPOINT, json=payload, timeout=60)
                    resp.raise_for_status()
                    data = resp.json()
                    df = utils.df_from_service(data)           # json/values ëª¨ë‘ ëŒ€ì‘
                    df = utils.normalize_youtube_df(df)        # ì‹œê°„/ìˆì¸  í”Œë˜ê·¸ ë“±
                    df = utils.ensure_url_columns(df)          # videoId â†’ url
                    df = utils.standardize_cols(df)            # view_countâ†’viewCount ë“± ê³µí†µ í‚¤ ì •ë ¬
                    st.session_state["yt_results"] = df
                    st.success(f"ì´ {len(df)}í–‰ ë¡œë“œ ì™„ë£Œ!")
                except requests.HTTPError as e:
                    st.error(f"HTTP {e.response.status_code}: {e.response.text[:500]}")
                except Exception as e:
                    st.error(f"ìš”ì²­/íŒŒì‹± ì‹¤íŒ¨: {e}")

    st.divider()
    st.caption("í˜„ì¬ ì—”ë“œí¬ì¸íŠ¸")
    st.code(ENDPOINT, language="text")

# =========================
# â†•ï¸ ì •ë ¬/ë­í‚¹ íƒ­
# =========================
with sort_tab:
    df = st.session_state["yt_results"].copy()
    if df.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ” ê²€ìƒ‰ íƒ­ì—ì„œ ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")
    else:
        st.subheader("ì •ë ¬ ê·œì¹™")
        left, right = st.columns([2,1])

        with left:
            cols = df.columns.tolist()
            default_primary = "publishedAt_local" if "publishedAt_local" in cols else cols[0]
            primary = st.selectbox("1ì°¨ ì •ë ¬ ì»¬ëŸ¼", cols, index=cols.index(default_primary))
            primary_asc = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ(1ì°¨)", value=False)

            secondary = st.selectbox("2ì°¨ ì •ë ¬ ì»¬ëŸ¼(ì„ íƒ)", ["(ì—†ìŒ)"] + cols, index=0)
            secondary_asc = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ(2ì°¨)", value=True)

            apply_sort = st.button("ì •ë ¬ ì ìš©", use_container_width=True)

        with right:
            st.markdown("**ê°€ì¤‘ì¹˜ ë­í‚¹(ì„ íƒ)**")
            use_rank = st.checkbox("Composite Score ì‚¬ìš©")
            if use_rank:
                w_recency = st.slider("ê°€ì¤‘ì¹˜: ìµœì‹ ì„±", 0.0, 1.0, 0.4, 0.05)
                w_views   = st.slider("ê°€ì¤‘ì¹˜: ì¡°íšŒìˆ˜", 0.0, 1.0, 0.4, 0.05)
                w_likes   = st.slider("ê°€ì¤‘ì¹˜: ì¢‹ì•„ìš”", 0.0, 1.0, 0.2, 0.05)
                w_short   = st.slider("ê°€ì¤‘ì¹˜: ì‡¼ì¸ (<=60s)", 0.0, 1.0, 0.2, 0.05)
                st.caption("â€» ê²°ì¸¡ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")

        if use_rank:
            df = utils.add_composite_score(df,
                                           w_recency=w_recency,
                                           w_views=w_views,
                                           w_likes=w_likes,
                                           w_short=w_short)

        if apply_sort:
            by_cols = [primary]
            asc_list = [primary_asc]
            if secondary != "(ì—†ìŒ)":
                by_cols.append(secondary)
                asc_list.append(secondary_asc)
            if use_rank and "score" in df.columns:
                by_cols = ["score"] + by_cols
                asc_list = [False] + asc_list
            df = df.sort_values(by=by_cols, ascending=asc_list)

        st.subheader("ê²°ê³¼ ì‹œíŠ¸")
        colcfg = {}
        if "url" in df.columns:
            colcfg["url"] = st.column_config.LinkColumn("YouTube", display_text="ì—´ê¸°")
        st.dataframe(df, use_container_width=True, height=520, column_config=colcfg)

        st.download_button(
            "CSV ë‹¤ìš´ë¡œë“œ",
            data=df.to_csv(index=False).encode("utf-8"),
            file_name="youtube_results_sorted.csv",
            mime="text/csv"
        )
