# pages/2_YouTube_Search_Table.py
import json
import pandas as pd
import requests
import streamlit as st
import config, utils

st.set_page_config(page_title="YouTube ê²€ìƒ‰ ì‹œíŠ¸ (Cloud Run)", layout="wide")
st.title("ğŸ“º YouTube ê²€ìƒ‰ ì‹œíŠ¸ (Cloud Run)")

config.render_key_inputs()
ENDPOINT = config.get("YT_SEARCH_ENDPOINT") or "https://search-youtube-417935223154.europe-west1.run.app/search-shorts"

# -----------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------------
ss = st.session_state
if "yt_results_raw" not in ss:
    ss["yt_results_raw"] = pd.DataFrame()   # ì›ë³¸(ê²€ìƒ‰ ê²°ê³¼)
if "yt_results_view" not in ss:
    ss["yt_results_view"] = pd.DataFrame()  # ì •ë ¬/í•„í„° ë°˜ì˜ ë·°

# -----------------------------
# íƒ­: ê²€ìƒ‰ / ì •ë ¬
# -----------------------------
search_tab, sort_tab = st.tabs(["ğŸ” ê²€ìƒ‰", "â†•ï¸ ì •ë ¬/ë­í‚¹"])

# â–¼ í˜ì´ì§€ ë§¨ ì•„ë˜ ê³µìš© í‘œë¥¼ ê·¸ë¦´ 'ì•µì»¤'
shared_table = st.container()

# === ğŸ” ê²€ìƒ‰ íƒ­ ===
with search_tab:
    st.subheader("ê²€ìƒ‰ ì˜µì…˜ (Cloud Run POST í˜¸ì¶œ)")

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    with c1:
        keyword = st.text_input("keyword*", placeholder="ì˜ˆ: debate, êµ­íšŒ ë³¸íšŒì˜, economy")
    with c2:
        days = st.number_input("days", min_value=1, max_value=30, value=7, step=1)
    with c3:
        max_results = st.number_input("max_results", min_value=1, max_value=200, value=100, step=1)
    with c4:
        top_n = st.number_input("top_n", min_value=1, max_value=50, value=10, step=1)
    with c5:
        rank_by = st.selectbox("rank_by", ["score","view_count","views_per_hour","like_count","likes_per_view"], index=0)
    with c6:
        fmt = st.selectbox("format", ["json","values"], index=0)

    run = st.button("ê²€ìƒ‰ ì‹¤í–‰", type="primary", use_container_width=True)

    if run:
        if not keyword.strip():
            st.warning("keywordëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        else:
            payload = {
                "keyword": keyword.strip(),
                "days": int(days),
                "max_results": int(max_results),
                "top_n": int(top_n),
                "rank_by": rank_by,
                "format": fmt
            }
            with st.spinner("Cloud Run í˜¸ì¶œ ì¤‘..."):
                try:
                    resp = requests.post(ENDPOINT, json=payload, timeout=60)
                    resp.raise_for_status()
                    data = resp.json()

                    # ì„œë¹„ìŠ¤ ì‘ë‹µ â†’ DF ì •ê·œí™”
                    df = utils.df_from_service(data)
                    df = utils.standardize_cols(df)
                    df = utils.normalize_youtube_df(df)
                    df = utils.ensure_url_columns(df)

                    ss["yt_results_raw"] = df
                    ss["yt_results_view"] = df.copy()  # ê²€ìƒ‰ ì§í›„ì—” ë·° = ì›ë³¸
                    st.success(f"ì´ {len(df)}í–‰ ë¡œë“œ ì™„ë£Œ! ì•„ë˜ ê³µìš© ì‹œíŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                except requests.HTTPError as e:
                    st.error(f"HTTP {e.response.status_code}: {e.response.text[:500]}")
                except Exception as e:
                    st.error(f"ìš”ì²­/íŒŒì‹± ì‹¤íŒ¨: {e}")

    st.caption("í˜„ì¬ ì—”ë“œí¬ì¸íŠ¸")
    st.code(ENDPOINT, language="text")

# === â†•ï¸ ì •ë ¬/ë­í‚¹ íƒ­ ===
with sort_tab:
    base = ss["yt_results_raw"]
    if base.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ” ê²€ìƒ‰ íƒ­ì—ì„œ ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”.")
    else:
        st.subheader("ì •ë ¬/ë­í‚¹ ê·œì¹™ (ì•„ë˜ ê³µìš© ì‹œíŠ¸ì— ì¦‰ì‹œ ë°˜ì˜)")
        left, right = st.columns([2,1])

        with left:
            cols = [c for c in base.columns.tolist() if c not in ("videoId", "url", "video_url")]
            default_primary = "publishedAt_local" if "publishedAt_local" in cols else cols[0]
            primary = st.selectbox("1ì°¨ ì •ë ¬ ì»¬ëŸ¼", cols, index=cols.index(default_primary))
            primary_asc = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ(1ì°¨)", value=False)

            secondary = st.selectbox("2ì°¨ ì •ë ¬ ì»¬ëŸ¼(ì„ íƒ)", ["(ì—†ìŒ)"] + cols, index=0)
            secondary_asc = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ(2ì°¨)", value=True)

        with right:
            st.markdown("**ê°€ì¤‘ì¹˜ ë­í‚¹(ì„ íƒ)**")
            use_rank = st.checkbox("Composite Score ì‚¬ìš©")
            if use_rank:
                w_recency = st.slider("ê°€ì¤‘ì¹˜: ìµœì‹ ì„±", 0.0, 1.0, 0.4, 0.05)
                w_views   = st.slider("ê°€ì¤‘ì¹˜: ì¡°íšŒìˆ˜", 0.0, 1.0, 0.4, 0.05)
                w_likes   = st.slider("ê°€ì¤‘ì¹˜: ì¢‹ì•„ìš”", 0.0, 1.0, 0.2, 0.05)
                w_short   = st.slider("ê°€ì¤‘ì¹˜: ì‡¼ì¸ (<=60s)", 0.0, 1.0, 0.2, 0.05)
                st.caption("â€» ê²°ì¸¡ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")

        # ì •ë ¬/ì ìˆ˜ ì ìš© ë²„íŠ¼
        apply_sort = st.button("ì •ë ¬ ì ìš© â†’ ì•„ë˜ ê³µìš© ì‹œíŠ¸ ì—…ë°ì´íŠ¸", use_container_width=True)

        if apply_sort:
            view = base.copy()
            if use_rank:
                view = utils.add_composite_score(view,
                                                 w_recency=w_recency,
                                                 w_views=w_views,
                                                 w_likes=w_likes,
                                                 w_short=w_short)
            by_cols = [primary]
            asc_list = [primary_asc]
            if secondary != "(ì—†ìŒ)":
                by_cols.append(secondary)
                asc_list.append(secondary_asc)
            # ì ìˆ˜ê°€ ìˆë‹¤ë©´ ìµœìš°ì„ 
            if "score" in view.columns and use_rank:
                by_cols = ["score"] + by_cols
                asc_list = [False] + asc_list

            view = view.sort_values(by=by_cols, ascending=asc_list)
            ss["yt_results_view"] = view
            st.success("ì •ë ¬/ë­í‚¹ ë°˜ì˜ ì™„ë£Œ! ì•„ë˜ ê³µìš© ì‹œíŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# -----------------------------
# â–¼ í˜ì´ì§€ í•˜ë‹¨: ê³µìš© ì‹œíŠ¸ (ë‘ íƒ­ì—ì„œ ê³µìœ )
# -----------------------------
with shared_table:
    st.divider()
    st.subheader("ğŸ“Š ê³µìš© ê²°ê³¼ ì‹œíŠ¸")
    df_view = ss["yt_results_view"]

    if df_view.empty:
        st.info("ì•„ì§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íƒ­ì—ì„œ ê²€ìƒ‰/ì •ë ¬ì„ ì§„í–‰í•˜ì„¸ìš”.")
    else:
        # UIì—ëŠ” ìˆ¨ê¸¸ ì»¬ëŸ¼ (ë‚´ë¶€ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)
        HIDE_COLS = ["videoId", "url"]

        # 2) í‘œì‹œìš© DF ìƒì„±
        df_display = df_view.drop(columns=HIDE_COLS, errors="ignore").copy()

        # 3) video_url ì»¬ëŸ¼ ìƒì„± ë³´ì¥ (ìš°ì„ ìˆœìœ„: ê¸°ì¡´ video_url â†’ url â†’ videoIdë¡œ ìƒì„±)
        if "video_url" not in df_display.columns:
            if "url" in df_view.columns:
                df_display["video_url"] = df_view["url"]
            elif "videoId" in df_view.columns:
                df_display["video_url"] = df_view["videoId"].apply(
                    lambda v: f"https://www.youtube.com/watch?v={v}" if pd.notna(v) else None
                )
            else:
                df_display["video_url"] = None

        # 4) ì œëª© ì»¬ëŸ¼ ë°”ë¡œ ë’¤ì— video_url ë°°ì¹˜
        title_col = "video_title" if "video_title" in df_display.columns else ("title" if "title" in df_display.columns else None)
        if title_col and "video_url" in df_display.columns:
            cols = df_display.columns.tolist()
            # ë¨¼ì € ìœ„ì¹˜ì—ì„œ ì œê±°
            if "video_url" in cols:
                cols.remove("video_url")
            # ì œëª© ë°”ë¡œ ë’¤ ìœ„ì¹˜ ê³„ì‚°
            insert_pos = cols.index(title_col) + 1 if title_col in cols else 1
            cols.insert(insert_pos, "video_url")
            df_display = df_display[cols]

        # 5) column_config: video_urlì„ ì•„ì´ì½˜ ë§í¬ë¡œ, ì¸ë„¤ì¼ì€ ì´ë¯¸ì§€ë¡œ
        colcfg = {}
        if "video_url" in df_display.columns:
            colcfg["video_url"] = st.column_config.LinkColumn(" ", display_text="â–¶ï¸")  # ìœ íŠœë¸Œ ì•„ì´ì½˜ ëŠë‚Œì˜ í”Œë ˆì´ ë²„íŠ¼
        if "thumbnail" in df_display.columns:
            colcfg["thumbnail"] = st.column_config.ImageColumn("ì¸ë„¤ì¼", width="small")

        # 6) ë Œë”
        st.dataframe(df_display, use_container_width=True, height=520, column_config=colcfg)

        # (ì„ íƒ) í™”ë©´ì— ë³´ì´ëŠ” ì—´ë§Œ CSVë¡œ ì €ì¥ (ìˆ¨ê¹€ ì—´ ì œì™¸)
        st.download_button(
            "CSV ë‹¤ìš´ë¡œë“œ(í‘œì‹œ ì—´ë§Œ)",
            data=df_display.to_csv(index=False).encode("utf-8"),
            file_name="youtube_results_view_display.csv",
            mime="text/csv"
        )
